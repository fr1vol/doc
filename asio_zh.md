## 多线程是一种错觉


[视频地址](https://www.youtube.com/watch?v=wxXIbaJBZlE&t=6s)

我将做一个简短的演讲，然后回答对在演讲之后提出的疑问。 今天的演讲不是介绍asio的教程或文档。 这期演讲更多的是可以使您对asio产生的思维和哲学有所了解，也是推动我在工作中运用的思想。

当人们提到并发一词时，他想到的事情就是解决线程涉及的问题的方法，包括抛出线程问题，并且这取决于依赖的编程语言和编程工作环境。 我今天要尝试谈论的是，线程实际是一种幻想。

真正需要的线程仅仅是一个抽象。 那么现在工作中的线程是什么。我说的是使用线程来执行网络连接，或者需要其他相关任务驱动的任务，我们真正在做的是使用线程作为协调网络操作的机制。

因此，实际上你的线程是一个状态机。并且是由以下这些实现的，包括栈帧，线程局部变量，寄存器，指令序列，程序计数器。关于这些重要的事情是那些线程有许多通用的抽象。 他们旨在解决很多不同的问题。不仅在网络层的阻塞，而且还使您可以在系统中CPU核心的硬件之间分解CPU绑定的工作。

因此，它试图通过单个通用操作解决实际涉及很多不同的用例。当涉及到网络时，如果您知道自己正在解决的问题，那么通常可以比以通用目标的抽象做得更好，并明确的是网络事件相关的IO任务。我们的情况实际上要比线程更容易。

这实际上是什么意思呢。很多次我和人们谈论过有关asio的问题，我记得很清楚，当我在XXX上发表评论时有人问我。等一下，我对喜欢使用独立连接或线程连接的典型设计人员感到非常满意，但仅出于示例的目的，就像任何其他普通的程序一样，琐碎的事情都会比这复杂得多。

但是我们这里是一个单线程的任务，该线程用以从套接字上读取字节数据，然后执行了某些操作。可能是使用http协议去查询数据库，这不重要。关键点是你可以使用专用线程来处理仅单个的链接。这就是启示之一：简化网络IO。

当你正确执行此代码时，或多或少都会发生，你的线程正在执行一个asio的函数read_some()，该函数可以读取套接字上的一些数据。第一件事时你的线程正处于运行状态，它将执行最近的网络系统调用指令，用以读取套接字上的一些数据。

数据并不是立即就能获取到，因此线程进入睡眠状态。在此期间，操作系统会从这里获取一些东西。一段时间后有人向你发送请求。现在接下来发生了什么。如果NIC说已数据包从网络到达网卡。 网卡触发一个中断以唤醒网络驱动程序，网络驱动程序做它所需要做的工作，如解码网络协议，然后将其传递给网络堆栈。网络堆栈可以完成TCP或UDP所需的操作，或执行诸如协议之类的活动。然后在结尾出进行上下文切换，唤醒正在处于休眠的程序并将其置于运行状态，以便你可以对刚刚到达的数据进行处理。

当你的连接数超过计算机中拥有的cpu或cpu内核数时会发生什么。非常简单的情况时，这里只有一台cpu机器，其中两个线程正在两个不同的套接字上执行读取操作。那么当你的数据报文到达时会发生什么。注意现在是多个数据报文同时到达。唯一NIC处理对网络驱动程序的多个中断。网络驱动程序将数据传递到网络堆栈。网络堆栈现在想传递数据给，并唤醒其中一个线程来执行， 但是它只有一个CPU，因此有许多唤醒一个线程来运行。因此，第一个线程唤醒，并且它对数据进行了处理。如数据库查询，这不重要。

如果你还记得之前的代码，那是一个简单的循环，即无限循环在套接字上调用read()函数。线程调用后续的read_some()，然后只有当NIC触发第二个线程唤醒时，然后处理最新的等待数据。这里发生了什么.

当思考涉及有关具体执行含义时，这本质是一个排队问题。我们有两个任务准备就绪，可以同时执行。这是要处理两个数据包，我们只能一个接一个地执行。运行每个任务的成本包括上下文切换到线程。 现在就规模而言，我的意思是非常依赖于您所使用的操作系统，上下文切换的成本很高，但是通常以成千上万个CPU周期（如放入指令）的方式对其进行度量，但是实际上 与从本地变量读取/写入值相比，这是一个昂贵的麻烦。因此，即使在该示例中，我正在学习谈论的是两个连接，这仍然是一个普遍的问题，如果您拥有的就绪连接甚至超过了可用CPU的数量。

这意味着这将会减小查询的吞吐能力，增加延迟。考虑以下程序处理这两个打开的套接字上的帧会发生什么情况，他涉及从传递数据开始的所有代码。然后进行上下文切换，返回，再次上下文切换，然后处理两个数据包。

在这里要意识到的时，这里有些特殊的成本，在这种特殊情况下实际上可以在这些数据包中分散掉的成本。这是上下文切换的成本。 如果我们能够批量处理两个事件，那么我们就可以在这两个事件之间节省上下文切换的成本。所以，我们认为在此示例中，我们可以删除其中一个上下文切换。


因此，正如我之前所说的那样，当您使用线程来协调网络时要记住的事情实际上就是状态机。 不必直接走向线程。因此，asio库的真正目的是允许您使用其他形式的状态机来自动化诸如网络IO之类的事情。 

所以我在这里有了一个非常简单的异步等效项，就像我们之前看到的频繁连接程序一样。 所以我们有一个socket，它只是对操作系统提出的socket的抽象。在这种情况下，我们将使用一个标准数组作为读取它的缓冲区。 现在这里的这些成员不太和普通的缓冲区一样。并且可能具有生命周期，现在我们需要显式地将许多生命周期扩展到异步网络IO中涉及的事物。 所以，阻碍实际异步操作的是这个成员函数进行读取操作。

那么我们开始使用的套接字发生了什么。 我们将此成员函数称为async_read_some（），相当于我们看到的阻塞read_some（）。 我们以想要读取日期的方式传递它。 但是这次，我们有了这个附加参数，该附加参数在此消息的末尾被调用，称为“在异步操作中完成”。


因此，与阻塞调用不同，这是异步的，实际上实际上会立即返回一些调用。一旦启动异步操作，该调用就会立即返回。 因此，时间流逝，然后当数据到达回调调用并传递错误代码时，告诉您是否成功，还是失败了，以告诉您失败的原因是什么，它告诉您传输的字节数。 一旦了解到错误码，下一步基本上等同于我们要做的事情，那就是此时只对数据做些事。我们没有显式的循环，在我认为返回并开始下一个操作做之前需要先经历一个循环的地方。

在异步世界中，我们需要链接回调函数，因此在这里我们完成了一些操作，如果我们不调用再次读取，然后又返回，然后开始下一个异步操作。 看起来像递归在正常的堆栈意义上并不是真正的递归。但是您得到的是一连串异步操作。完成第一次同步读取后，下一个开始读取下一个异步，依此类推直到连接关闭等等。

现在让我考虑屏幕下方这个io_service.run()。现在在asio中以更通用的术语IO_service对象表示您的程序和操作系统网络调用之间的链接。 但特别是在此程序中，它充当事件循环。 因此，当您在io_service上调用run()时，它将处理与异步程序关联的所有事件。

将io_service.run()放入main函数中，以驱动程序的事件处理。现在，如果我们回到前面的示例，则在单个CPU上运行两个连接。 因此，我们有两个独立的会话对象。它们正在同时执行异步网络IO。所以现在发生的是NIC中断了网络驱动器，以尽可能地处理新帧。然后最后它只有一个线程可以唤醒， 因为现在有一个上下文切换，并且一旦该线程运行了足够的线程，它将运行两个异步完成处理程序，而不是一个第一个会话对象，然后在第二个会话中完成该异步处理程序。

等一下，我是说我们真的在会话对象之间在这里进行上下文切换吗？ 我们实际上获得了什么吗？ 实际上，是的。 因为在使用线程来表示每个会话之前，您需要将上下文从线程切换到另一个，并以数千个周期进行衡量。 专门通过所有回调对象安装状态机的专用事件循环可以在数十个周期内在不同状态机之间进行切换。 因此，我们要讨论的是成本之间的两个数量级差异。我们现在处理这两个数据帧的方法就是削减其中一个上下文切换。 现在，如果您按比例放大时只有两个，那么本质上是在上下文切换中进行保存就是其中之一。

接下来的问题是处理少量链接情况时，有人说我还是不喜欢使用异步的东西，宁愿每个连接分配一个线程的设计。考虑，当一切正常运行时会发生什么。你有两个CPU和两个连接，当数据证正确到达时会发生什么。数据通过NIC到达驱动，驱动到达网络堆栈。网络堆栈唤醒两个线程，这俩线程现在在两个不同的cpu上运行。因此，最后的两个步骤是同时发生的。所有，就处理我们收到的数据包所花费的时间而言。我们将节省的时间用总的绝对时间（两个中较长的时间）来表示，因为这些昂贵的上下文切换是在同时发生的。

首先要考虑的是您的两个线程，会话，连接实现是否实际上是独立的。在这个简单的echo程序中，它是这样的，只有某些类型的问题确实具有这些独立的独立对象，您经常使它们访问某些共享的数据结构，也许它们是存在查询数据库的一个连接。他们之间经常共享一些东西，它们都需要访问，然后，如果您有多个线程访问共享资源，那么典型的解决方案是使用互斥锁。当数据包到达网络堆栈时，会发生什么。 当两个线程都可用时。但是只用其中一个线程能够立即获取互斥锁，可以访问资源，第二个线程无法访问该资源，然后再次尝试获取该互斥锁，直到释放互斥锁为止。

所以现在发生的是，我们之前节省的必须执行的两个上下文切换时间花费，相当于白节省了，第二个线程然后进入睡眠状态。现在如果我们已经为该模型使用异步编写了该程序。那么我们认为这两个事件都在运行相同的代码，因此我们知道两个事件都不能同时运行。 因此不一定需要互斥量。 我们可以找到所有在一个线程中运行的应用程序代码。因此，当我们运行第一个异步程序时，我们在此处执行了一些操作，不需要进行任何锁定。它返回并运行此第二个会话的数据。保证不会与另一个会话同时运行。。它保证不会与另一个同时运行。因此它不需要做锁定，它甚至不会在此处显示，您也没有额外的上下文切换的惩罚。

因此，您不必支付这笔额外的费用。一个同样完全相同的问题应该考虑您的线程连接是否确实为每个连接添加一个线程。因为许多系统必须同时处理入站和出站数据，所以我们通常只有一个线程正在执行读取以等待数据到达。我们有第二个线程，它使数据包或某种队列的消息出队，然后将数据写入套接字。和两个线程执行函数与单个连接相关，提出了相同的问题，同样，我们还需要使用互斥锁来保护共享的数据。然后，由于两个线程同时被唤醒，我们遇到了完全相同的问题。 因为同时read和write或他们在做的事情。第二个线程无法获取互斥锁，然后返回睡眠状态。

现在再一次。在异步情况下，我们没有这个问题，因为我们保证只有一个线程在运行我们所有的网络状态机。所以我们仍然不需要互斥体来访问共享状态。我们可以将多个任务链与单个会话相关联。 屏幕还不够大。请在这里听，但是如果您认为除了此操作之外，还执行负责读取软件数据的任务链的函数，我们可能有一个发送功能，而我们可能还有另一个发送心跳信号的功能，另一个可以确定是否需要终止连接的功能，因为它已经闲置了一段时间。 我们拥有所有这些状态机，它们可以共同管理整个会话，我们仍然不需要互斥保护。

这就是我正在研究的东西变得更加有趣的地方。如果我们考虑与中断相关的代价，那将是一件好事，现在您已经在典型的基于服务器的机器中知道了。 这些天将会发生的事情是，我们将拥有一个系统体系结构，其中您有两个或更多个物理插槽，每个插槽包含多个核心。您的网卡实际上可能更接近另一个。 因此，就从网卡传入的数据而言，并非所有cpu内核都是花费相同的时间。将数据传递给一个核心比另一个核心更昂贵。因此，当数据到达时会发生什么情况，好的，在我们的条件模型中，第一个线程通过它一切都很好，因为所有数据都已经存在，当我说“本地”时，我正在使用它作为术语来覆盖高速缓存，但是在新架构上，您可以拥有实际的存储库，内存等等 ，也比另一个接近一个cpu。

操作系统可能已经将与这些数据包相关联的数据放在一个线程可以访问的位置，但是实际上自由访问非常昂贵，因为它们可能正在另一个物理套接字上运行。 当你开始异步运行程序的一个优点是，更改程序非常容易。 这样您就可以选择一个CPU，当这些事件到达并处理这些当前数据包时，我们可以保证，仍在处理多个会话中的事件。 所以这就像一个特定于Linux的池，但是如果您选择操作系统，就可以这样做。我们保证了io_service在特定的cpu上运行，然后我们可以确保配置了我们的计算机，以便网卡的中断转到特定的物理CPU，然后我们用于处理连接的代码也可以在同一线程中运行。

您不一定需要该代码即可执行此操作，具体取决于您的操作系统，实际上可能有许多类似的任务，例如新任务或更多新问题。因此，您可以在程序安装程序外部实际运行您的代码 一个东西 。问题是，如果我们使用连接读取此程序，也许我们有一个十六核的cpu，而我们必须处理十个运行到cpu的内核，我们必须处理十个连接运行到cpu中，我们不能保证总有一个空闲的cpu可以处理所有同时到达的数据，其中一些可能最终会在我们所使用的其他套接字上运行并将其全部限制在 相同的物理CPU。 但是现在我们又遇到了排队问题，因为其中一个可能正在cpu上运行，并且不会放弃，然后另一个必须进入睡眠状态。

根据您所从事的工作领域的不同而有所不同。实际上，我们可以消除上下文切换的成本，但这对运行环境系统是不利的（更耗费cpu），虽然我没有说。我们不必更改此代码。完全相同的。我们要做的是更改事件循环的驱动方式。所以前面我的意思是，您可以在这里看到它，但是有一个io_service运行。现在，当您运行io_service时，它会阻塞。因此，此时并没有真正的事件，然后进入睡眠状态，然后它们启发了上下文唤醒它。现在，另一方面，如果没有可用的事件，轮询现在将不起作用，然后返回。关键是我们实际上可以运行该代码，只是继续进行而没有任何事件，让我们再试一次。您知道我认为可能存在混乱的定义，但实际上在这种程序中，它实际上起了很大的作用 因此，如果甚至需要破解线程或永不入睡，那么它永远也不会支付与唤醒相关的上下文切换成本。本质上一直在询问您的网络并直到为我获取到任何数据。所以这就是发生的情况。 因此，当数据确实到达网卡时，会不断处理网络数据包中的最新数据，然后将其传递出去，但这只是暂时保留在那里（网络堆栈），等待线程获取或只是接受它。


现在想想，这取决于您的工作量，您实际上可以逐层绕过内核。您知道其中的网卡实际上来自内核，这就是所谓的内核旁路层（kernel bypass layer），这实际上是一种方法 直接从网卡中获取数据而无需通过操作系统网络状态。并且取决于使用哪种方式，因此在Linux上，它们中的一些会通过熟悉LD-preload的方式出现，从而可以替换 操作系统提供的具有您自己的自定义版本的功能。因此，当您在套接字上正常调用read时，将属于网络堆栈的操作系统版本。当您处理此内核绕过层时，实际上会发生什么 ，相反它是与函数挂钩，并且说是内核网络通道的大门，它在使用供应商提供的最新操作，可能是ip堆栈。

教你使用DMI或其他的方法访问副本，直接读取该数据。这样做的好处是，我在谈论中断之前一直在谈论上下文切换，这是很昂贵的开销。如果我们及由此功能（DMI等特殊手段），我们从系统中完全消除了中断，我们刚刚将数据从NIC传到了某个地方，但可能复制到了某个地方，但我们的线程只是 在整个功能上自旋，永不休眠的获取数据。这基本上是从诸如延迟之类的角度来看的，它会尽可能降低它，但这样做确实要付出代价，因为您的cpu的运行速度为100％ 始终保持最大功率。

因此，本节可以继续进行，只是尝试给出一些您可能想要的概述，但是当您使用asio之类的东西来启动网络时，考虑一下底层发生的事情实际上是值得的，比如没有系统中断的时候到来等等。做得比线程性能快得多，可以更快地接收，低延迟，但是您应该如何精心设计程序以使用它呢？ 因此，如果您要使用asio作为设计建议的首选方法，那么下一节将进行简要的介绍。

现在，有了一个具体的新案例来解释这些方法。所以，我得到的是一个非常简单的tcp代理，因此与前面的示例不同，我们只是在套接字上echo了一些东西，而现在我们有了一些起作用的东西 作为客户端和服务器之间的中介，它的工作纯粹是传递数据，在某些情况下，您可能知道这可能是通过防火墙或进行有效检查。本质上，您的会话负责同时在两个方向上传输数据。因此，仅在此处设置代理的具体步骤是什么，当客户混合使用并建立与上游服务器的连接时，等待客户连接到它，然后便开始传输 双向数据。


所以这是我按照优先顺序提出的建议。我认为我们将要说出这种一般性建议，使用stl中的容器如vector容器就是一个好选择。因此，当涉及到这类事情时，单线程应该是不错的选择，简单的原因是不必担心显式的锁等等。多线程访问共享资源可能会出错，必须保护对变量的访问。因此所有的内容都在一个线程上运行。我将在这里讨论这个话题，我想也许这对于您可能需要处理较长时间运行的任务的情况非常简单，这意味着这一点。 然后我将使用两种多线程设计方法。


这是单线程的，我们已经说过了。 我说过我会推荐这是首选的设计选项，但是您需要记住要给所有这些完成句柄做一个限制，就像回调保持使它们简短而不会阻塞一样。因为您知道如果其中一个句柄去尝试写入已加载的数据库会发生什么，如果该阻塞持续了几秒钟，那么没人会知道不会再处理其他会话。因此，您确实需要注意好您所有的句柄，需要注意他们在做什么，这样就不会进入睡眠状态，也不会阻挡后面的所有函数。 因此，我们的程序看起来像什么。我以这种方式构造了代码，以使状态机如何变得更加清晰（如果您喜欢程序与程序之间的联系）。

我不能总是保证在阻塞时可以缩短我的处理程序。我可能会执行一些需要链接的任务，但是要链接要执行的时间段，那么我该怎么办。所以我的建议是保持与网络相关的代码仍然是单线程的，因为状态机通常会在会话中保持很多复杂性，而只是将长时间运行的任务传递给某些后台线程或线程池或某些可执行的代码来执行任务。当结果准备好时，我们要求返回执行新获取的线程，然后继续进行状态机的下一步。

因此，如果出于这些因素的考虑，我将举个例子。添加一个个额外的步骤。 假设我们接受了来自客户端的新连接后，就需要再次检查白名单中的ip地址，但是白名单中可能包含数百万个地址，并且该地址正在大城市的数据库中运行。您不知道要花多长时间，所以，我的意思是，当您在结果中得到答案时，您便会成为观察者。 所以我不打算展示整个状态机，我只是将这个任务插入connect之间，所以我处于async_accept和connect之间。所以现在发生什么了，我们现在是async_accept了。 这是我们将下一步发布到该线程池中的适当方法。这些是函数，它们确实起作用，但是您可以使用自己的线程，这样可以长时间运行，这样就可以了，然后您需要执行 将结果发布回去完成创建的工作，然后继续其余的工作。



现在显然有一个缺点，那就是您现在需要为此方向的每个步骤支付上下文切换的花费，因此需要权衡了这个长期运行的任务保留在网络中的开销，哪个成本更高。因此，您需要确定您对它的特殊用途是什么。 如果您的要求是处理的所有连接数量级在千万级别的，那么任何可能花费数秒钟的任务都应该考虑，那将是不可接受的。所以这是一种方法，因此请记住，这是我的优先推荐的建议。

下一个将要运行多个子任务，现在io_service表示事件循环，因此它将运行其中的一个。 并且我们将在我们的计算机中分布多个cpus。 所以现在发生的是，当连接被接受时，它将把您带到特定的io_service。因此，您需要能够以某种方式对会话对象进行分区。 我有个例子，我们每天都在工作，可能还有其他的，根据分配的位置，你知道更好的聪明的方式。 知道您实际上是在多个cpus上分散工作负载的优势。 但是通常可能发生的情况是，如果它们确实阻塞了您，而您现在只是在阻塞特定分区上的阻塞而其他服务执行的特定服务上，那么您仍然应该缩短阻塞时间并保持阻塞，这显然是可以的，但是可以让您更多地利用 可用的cpu。

我什么时候建议您实际使用此模型，您会知道切换到该模型，我会说大多数应用程序可能是不认为与网络状态机相关的处理是否已经消耗了100％的cpu，如果我基本上知道的话您已经达到了将它们作为瓶颈一次运行的地步，并且您可能希望考虑在cpus的倍数上运行。或者这不是资源限制，但可能需要等待时间，因此分配了太多的负载到一个CPU。这样就发生了排队，您无法及时响应消息，因为队列中的项目太多。因此，通过将负载分散到多个CPU上，您就可以响应此消息。现在的局限性是，您可能应该而不是使用在消息传递类型的模型之间共享的共享资源，这样您就不会结束让一个工作分区等待互斥量，而可能等待另一个他们试图使所有内容保持异步，甚至程序中的通信对象也是如此。

即使是这种模型，我们实际上也根本不需要修改程序，我们的tcp代理仍然是单线程的，如果您愿意，我们可以有多个单线程。因此，我们仍然不需要互斥或其他任何东西，而下一个。以及最终设计的选择，好的，我无法划分独立对象。

我真正想做的是我想通过一个IO_service上的多个线程，所以我希望我的循环能够跨多个线程服务工作。您知道我们已经接受了基本的连接，到目前为止，我们只进行了基本的连接，就像与连接相关的单个操作链一样，但是从现在开始，我们开始分离现在的状态机同时运行，但是您必须处理一个事实，这是因为我们有多个线程在为io_service提供服务。这些线程可以运行这两个小任务，以便在此端口上更好地并行运行。而且我们的代理服务器中也有一些链也延伸到套接字模型。所以这必须知道我们在做的更好。


到目前为止，我们已经完成了基本的连接，但是我们只进行了一次基本的连接，但是自从我们到现在为止，我们开始分离现在正在同时运行的状态机，但是必须认识一个事实，这是因为我们有多个线程在为io_service提供服务。这两个线程可以同时运行这两个任务，以便在此处更好地并行运行。 而且我们的代理中也有一些链也可以到达套接字模型。所以这必须知道我们在做的更好。

因此，线程线程中最重要的事情可能是，尤其是从互斥锁中看到的线程。现在，您又回到了一个问题，我们已经将我们的一个线程最终可能重新进入睡眠状态，因为它无法获取 互斥锁，因为另一个当前处于该互斥锁上，所以在那里停留了另一种解决方案。因此，除以asio的解决方案是，希望网络状态机由所谓的strand执行。


现在，它是一个对象，您可以用来确保可以用于确保某些异步操作组。与它们相关联的完成处理程序永远不会同时运行，并且它们以FIFO顺序运行。因此，通常来说，您使用它们的方式是说，通过我们的接收者我们的代理，我们希望其中的所有这些处理程序都运行同一链。因此，当您使用strand时，您将执行此操作。当您启动异步操作时，我们将把完成处理程序包装在我们的strand中。这告诉asio该回调与strand相关联，可以在中执行我们将对组成该会话的所有异步操作执行此操作，所以现在发生的是，asio我们将这两个部分并行运行，即使其中两个已经同时运行。 asio确保了他们不会在同一工作上处于中心位置。

就像一个互斥锁，如果其中一个互斥锁获得互斥锁，则互斥锁将与另一个互锁进入睡眠状态。排在后面的队列操作中，然后在第一次完成时又获得了很多好处，然后又开始运行另一个。好事是，虽然这使逻辑可以通过会话进行评估，但您可以在多个会话上运行好的核心，他们仍然可以并行执行，我喜欢互斥锁，如果其中一个线程获得互斥锁，而另一个线程将进入睡眠状态。那么asio将如何使用strand，strand处于忙碌状态。我只是当第一个句柄完成时，将第二个处理程序排入队列，然后运行另一个。这是一件好事，因此，这样可以使逻辑式来交互访问，可以在内核上良好的运行了多个会话，它们仍然可以并行执行

所以我认为，如果您有多个这些指令，则您会引导您并行访问我们组中的同一会话，但是不同的会话对象仍然能够在相反的cpu上运行完成处理程序。所以现在当数据到达传递时会发生什么，第一个计时器立即运行，第二个处理程序假定该事件不在同一批中出队，只是排队到该线程上，然后该线程中的其他线程就可以继续为任何线程服务可以使用其他事件。现在，如果您使用此模型，那么实际上可以让处理程序长时间阻塞是可以的，但实际上由您决定要运行多少个IO_service线程来启用多少并发性。因此，如果您认为此处的asio充当线程池，并通过调用服务轮询将其运行到池中，则该服务将成为正在运行的网络事件。

我只是想为这些建议中的内容添加一个，无论你选择哪个，注意中断和cpu亲和力等内容仍然很重要，即使您有处理网络事件的线程池中可能看不到多个物理套接字，您可能需要确保控制所有与网卡相同的物理套接字。因此，当数据到达时，实际上方便地在io_service上为它们提供服务的所有线程都在本地和以前一样，您仍然可以执行此操作，而不必更改代码，只需确保事件循环与大多数这些事情相关联即可。